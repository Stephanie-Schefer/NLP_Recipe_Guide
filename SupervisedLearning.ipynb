{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fec1a3b-a390-4703-b2ca-b4915e32a448",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "# Unsupervised Learning\n",
    "- https://projector.tensorflow.org/\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88279280-85f0-46e5-b278-745d837531f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'title', 'directions', and 'ingredients' into a single text field for clustering\n",
    "whole_df['combined_text'] = whole_df['title'] + ' ' + whole_df['directions'] + ' ' + whole_df['ner']\n",
    "\n",
    "\n",
    "    # word to vec here\n",
    "    # sentence bert from hugging face instead of tfidf get embeddings back 1024 length. text in recipe\n",
    "    # use tsne transformation\n",
    "    # results in length 3 for each recipe\n",
    "    # do the clustering on these 3. \n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_tokens(text):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=True,return_tensors='pt')\n",
    "    # Get BERT embeddings for each token\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "    return embeddings\n",
    "\n",
    "whole_df['embeddings'] = whole_df['combined_text'].apply(get_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6fca1-9401-4d6c-b76d-82f99b4534e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'title', 'directions', and 'ingredients' into a single text field for clustering\n",
    "whole_df['combined_text'] = whole_df['title'] + ' ' + whole_df['directions'] + ' ' + whole_df['ner']\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "    # word to vec here\n",
    "    # sentence bert from hugging face instead of tfidf get embeddings back 1024 length. text in recipe\n",
    "    # use tsne transformation\n",
    "    # results in length 3 for each recipe\n",
    "    # do the clustering on these 3. \n",
    "\n",
    "\n",
    "whole_df['combined_tokens'] = whole_df['combined_text'].apply(preprocess_text)\n",
    "\n",
    "# Convert tokenized text into TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "tfidf_matrix = tfidf.fit_transform(whole_df['combined_tokens'])\n",
    "\n",
    "# K-Means clustering\n",
    "num_clusters = 5  # You can adjust the number of clusters as needed\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "# Assign cluster labels to the DataFrame\n",
    "whole_df['cluster_label'] = kmeans.labels_\n",
    "\n",
    "# Displaying cluster assignments\n",
    "cluster_results = pd.DataFrame({\n",
    "    'Recipe': whole_df['title'],\n",
    "    'Cluster': whole_df['cluster_label']\n",
    "})\n",
    "\n",
    "print(cluster_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a7b6e-9817-4081-bfb2-c38f1876e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality reduction for visualization (if the TF-IDF matrix is high-dimensional)\n",
    "svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "tfidf_matrix_reduced = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Add cluster labels and reduced dimensions to DataFrame\n",
    "whole_df['X'] = tfidf_matrix_reduced[:, 0]\n",
    "whole_df['Y'] = tfidf_matrix_reduced[:, 1]\n",
    "\n",
    "# Plotting clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x='X', y='Y', hue='cluster_label', palette='viridis', data=whole_df, legend='full')\n",
    "plt.title('Clustering of Recipes based on Titles, Directions, and Ingredients')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cd2a9-39eb-445a-9c6f-0ca2603151ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TF-IDF matrix\n",
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x, lowercase=False)\n",
    "tfidf_matrix = tfidf.fit_transform(whole_df['combined_tokens'])\n",
    "\n",
    "# K-Means clustering\n",
    "num_clusters = 5  # Adjust as needed\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "kmeans.fit(tfidf_matrix)\n",
    "\n",
    "# Assign cluster labels to the DataFrame\n",
    "whole_df['cluster_label'] = kmeans.labels_\n",
    "\n",
    "# Calculate Cluster Centroid\n",
    "cluster_centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Count in Cluster\n",
    "count_in_cluster = whole_df['cluster_label'].value_counts().sort_index()\n",
    "\n",
    "# Assign Cluster ID\n",
    "whole_df['cluster_id'] = whole_df['cluster_label'] + 1  # Adding 1 to start cluster ID from 1\n",
    "\n",
    "# Add Cluster Centroid, Count in Cluster, and Cluster ID to a new DataFrame\n",
    "cluster_summary = pd.DataFrame({\n",
    "    'Cluster ID': whole_df['cluster_id'].unique(),\n",
    "    'Count in Cluster': count_in_cluster.values,\n",
    "    'Cluster Centroid': cluster_centroids.tolist()\n",
    "})\n",
    "\n",
    "print(cluster_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
